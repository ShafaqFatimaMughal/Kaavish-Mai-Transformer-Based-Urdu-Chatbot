{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLErHcwRIzqi",
        "outputId": "64bd6aba-b6a9-4dee-ae92-30bdc3e10669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.7/dist-packages (7.6.0)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.7/dist-packages (from praw) (2.3.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.7/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.7/dist-packages (from praw) (1.4.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2.1->praw) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "# Installations\n",
        "!pip install praw\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCUOC3pQINd8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import praw\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF5CO1hDJLm7"
      },
      "outputs": [],
      "source": [
        "# Initializing Reddit Class\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"RV9fcx4CzD_htsS4hrF_9w\",\n",
        "    client_secret=\"LKsX3rScHYgq0PHokFilLZPzwjcJGQ\",\n",
        "    user_agent=\"Mai\",\n",
        "    check_for_async=False\n",
        ")\n",
        "\n",
        "context_len = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePOxNLs2tJ-7"
      },
      "outputs": [],
      "source": [
        "def get_all_leaves(submission):\n",
        "  data = {}\n",
        "  # Modified DFS to get all leaf comment ids/ comments that do not have children\n",
        "  # And also maintain a dict with parent and comment text info for each comment\n",
        "  submission.comments.replace_more(limit=0)\n",
        "  comment_stack = submission.comments[:]\n",
        "  all_leaves = []\n",
        "\n",
        "  while comment_stack:\n",
        "      comment = comment_stack.pop(0) # Comment visited\n",
        "      data[comment.id] = {\"parent_id\":comment.parent().id, \"body\":comment.body}\n",
        "      if len(comment.replies) == 0: # Leaf is reached\n",
        "        all_leaves.append(comment.id)\n",
        "      comment_stack[0:0] = comment.replies\n",
        "\n",
        "  return all_leaves, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OnVgQ53toOx"
      },
      "outputs": [],
      "source": [
        "def get_paths(submission_id, leaves, data):\n",
        "  # Get all comment paths from root/ top level comment \n",
        "  paths = []\n",
        "\n",
        "  for leaf in leaves:\n",
        "    path = []\n",
        "    x = leaf\n",
        "\n",
        "    while (data[x][\"parent_id\"] != submission_id): # Till the comment id is not eq to post id/ till top level comment not reached\n",
        "      if data[x][\"body\"] == \"[deleted]\" or data[x][\"body\"] == \"[removed]\":\n",
        "        x = data[x][\"parent_id\"] # Update x eachtime in any case\n",
        "        continue\n",
        "      path.append(data[x][\"body\"])\n",
        "      # print(data[x][\"body\"])\n",
        "      x = data[x][\"parent_id\"] # Get parent of comment. Update x eachtime in any case\n",
        "  \n",
        "    # print(data[x][\"body\"])\n",
        "    if data[x][\"body\"] != \"[deleted]\" or data[x][\"body\"] == \"[removed]\": # For the leaf node\n",
        "      path.append(data[x][\"body\"])\n",
        "    paths.append(path)\n",
        "\n",
        "  return paths  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0StQfh-5kws"
      },
      "outputs": [],
      "source": [
        "def filter_paths(comment_paths, min_comments=context_len+1):\n",
        "  # Only choose those paths that have atleast the minimum context length\n",
        "  final_comment_paths = []\n",
        "\n",
        "  for path in comment_paths:\n",
        "    if len(path)>= min_comments:\n",
        "      final_comment_paths.append(path)\n",
        "  return final_comment_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnfzHjMEEvjY"
      },
      "outputs": [],
      "source": [
        "def create_df(paths):\n",
        "  columns = ['response', 'context'] \n",
        "  columns = columns + ['context/'+str(i) for i in range(context_len - 1)] # We need more context columns according to content_len\n",
        "  dataframe = pd.DataFrame(columns = columns) # Init dataframe with cols \n",
        "\n",
        "  for path in paths:\n",
        "    data = {}\n",
        "    data[\"response\"] = path[0] # Leaf comment in a path is the response\n",
        "    data[\"context\"] = path[1] # (Leaf-1) makes context\n",
        "\n",
        "    for i in range(2, context_len+1): # (Leaf-i) to root/ top level comment make subsequent contexts\n",
        "      context_num = i-2\n",
        "      data[\"context/\"+str(context_num)] = path[i]  \n",
        "    dataframe = dataframe.append(data, ignore_index=True) # Dictionary becomes one instance of dataframe\n",
        "\n",
        "  return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rvifh6rn06r"
      },
      "outputs": [],
      "source": [
        "def scrape_subreddit(subredit):\n",
        "  posts = []\n",
        "  # Get all posts from given subreddit \n",
        "  # Save all the details of each post in in dataframe\n",
        "  subreddit = reddit.subreddit(subredit) \n",
        "\n",
        "  print(\"Retreiving posts...\")\n",
        "  for post in subreddit.hot(limit=500):\n",
        "      posts.append([post.title, post.url])\n",
        "  \n",
        "  for post in subreddit.top(limit=500):\n",
        "    if post not in posts:\n",
        "      posts.append([post.title, post.url])\n",
        "  \n",
        "  for post in subreddit.new(limit=500):\n",
        "    if post not in posts:\n",
        "      posts.append([post.title, post.url])\n",
        "  \n",
        "  for post in subreddit.rising(limit=500):\n",
        "    if post not in posts:\n",
        "      posts.append([post.title, post.url])\n",
        "  \n",
        "  print(\"Retreived posts!\")\n",
        "  # posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
        "  posts = pd.DataFrame(posts,columns=['title', 'url'])\n",
        "  print(posts)\n",
        "\n",
        "  urls = posts['url'] # Select just the urls of each post\n",
        "\n",
        "  dataframes = []\n",
        "  image_num = 0\n",
        "  small = 0\n",
        "\n",
        "  # Putting everything together \n",
        "  # For each url/post, get the list of comment threads that meet the criteria and make a dataframe for each post \n",
        "  print(\"Finding Useful Threads...\")\n",
        "  for i in tqdm(range(len(urls))):\n",
        "      if urls[i].split(\".\")[-1] in [\"jpg\", \"png\"]:\n",
        "          image_num += 1\n",
        "          continue\n",
        "      try:\n",
        "        submission = reddit.submission(url=urls[i])\n",
        "        children, data = get_all_leaves(submission)\n",
        "        comment_paths = get_paths(submission.id, children, data)\n",
        "        \n",
        "        p = filter_paths(comment_paths)\n",
        "        if p !=[]:\n",
        "            df = create_df(p)\n",
        "            dataframes.append(df)\n",
        "        else:\n",
        "            small += 1\n",
        "      except:\n",
        "        continue\n",
        "  print(\"Found Useful Threads!\")\n",
        "\n",
        "  return dataframes, small, image_num # Return all dataframes and stats for the subreddit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subreddits = ['Periods', 'menstruation', 'badwomensanatomy', 'TwoXChromosomes']\n",
        "\n",
        "for subreddit in subreddits:\n",
        "  print(\"-------------- WORKING ON SUBREDDIT:\", str(subreddit), \"--------------\")\n",
        "  dataframes, small, image_num = scrape_subreddit(subreddit)\n",
        "  print(\"Total Usable DataFrames:\", len(dataframes))\n",
        "  print(\"Small, Unusable DataFrames:\", small)\n",
        "  print(\"Image Posts:\", image_num)\n",
        "\n",
        "  # For each subreddit, just concat the dataframes corresponding to each post of the subreddit as one post\n",
        "  final_df = pd.concat(dataframes, ignore_index=True)\n",
        "  print(\"Number of instances in concat DF:\", final_df.shape[0])\n",
        "  \n",
        "  # Saving the dataframe\n",
        "  fname = subreddit+'.csv' \n",
        "  final_df.to_csv(fname)\n",
        "  files.download(fname)\n"
      ],
      "metadata": {
        "id": "ASKLnMjzi400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12002455-2c11-4d2e-da85-ddecefbf50df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- WORKING ON SUBREDDIT: Periods --------------\n",
            "Retreiving posts...\n",
            "Retreived posts!\n",
            "                                              title  \\\n",
            "0                         COVID Vaccine and Periods   \n",
            "1                         Am I Pregnant? Megathread   \n",
            "2              Does anyone dread their periods too?   \n",
            "3                 So this just came out of me.. um?   \n",
            "4                             Period insomnia sucks   \n",
            "...                                             ...   \n",
            "1519                                Inducing period   \n",
            "1520  Passed out from cramps - is the alc to blame?   \n",
            "1521                                  Period early?   \n",
            "1522    Is it normal to get cramps once you hit 18?   \n",
            "1523                          Light brown discharge   \n",
            "\n",
            "                                                    url  \n",
            "0     https://www.reddit.com/r/Periods/comments/oxez...  \n",
            "1     https://www.reddit.com/r/Periods/comments/w9nz...  \n",
            "2     https://www.reddit.com/r/Periods/comments/yj5d...  \n",
            "3                 https://www.reddit.com/gallery/yj7tvq  \n",
            "4     https://www.reddit.com/r/Periods/comments/yj4q...  \n",
            "...                                                 ...  \n",
            "1519  https://www.reddit.com/r/Periods/comments/yiu8...  \n",
            "1520  https://www.reddit.com/r/Periods/comments/yiou...  \n",
            "1521  https://www.reddit.com/r/Periods/comments/yiu4...  \n",
            "1522  https://www.reddit.com/r/Periods/comments/yih4...  \n",
            "1523  https://www.reddit.com/r/Periods/comments/yisp...  \n",
            "\n",
            "[1524 rows x 2 columns]\n",
            "Finding Useful Threads...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1524/1524 [32:30<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Useful Threads!\n",
            "Total Usable DataFrames: 26\n",
            "Small, Unusable DataFrames: 1043\n",
            "Image Posts: 434\n",
            "Number of instances in concat DF: 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_95ec46cd-4dc8-4b3c-b5cf-7e47bd9fcc90\", \"Periods.csv\", 187949)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- WORKING ON SUBREDDIT: menstruation --------------\n",
            "Retreiving posts...\n",
            "Retreived posts!\n",
            "                                                  title  \\\n",
            "0                                        Periods in 30s   \n",
            "1                                        Toilet anxiety   \n",
            "2                                      Digestive issues   \n",
            "3                         IBS and Menstruation Research   \n",
            "4                                  Is 44 cycles normal?   \n",
            "...                                                 ...   \n",
            "1519   Missed period but pregnancy test shows negative?   \n",
            "1520  Recently diagnosed with hypothyroidism. I have...   \n",
            "1521                                    treating cramps   \n",
            "1522  Venting/ 20.5 yo that has started getting two ...   \n",
            "1523                                           Spotting   \n",
            "\n",
            "                                                    url  \n",
            "0     https://www.reddit.com/r/menstruation/comments...  \n",
            "1     https://www.reddit.com/r/menstruation/comments...  \n",
            "2     https://www.reddit.com/r/menstruation/comments...  \n",
            "3     https://www.reddit.com/r/menstruation/comments...  \n",
            "4     https://www.reddit.com/r/menstruation/comments...  \n",
            "...                                                 ...  \n",
            "1519  https://www.reddit.com/r/menstruation/comments...  \n",
            "1520                https://i.redd.it/0pcuci1ihiw91.jpg  \n",
            "1521  https://www.reddit.com/r/menstruation/comments...  \n",
            "1522  https://www.reddit.com/r/menstruation/comments...  \n",
            "1523  https://www.reddit.com/r/menstruation/comments...  \n",
            "\n",
            "[1524 rows x 2 columns]\n",
            "Finding Useful Threads...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1524/1524 [48:16<00:00,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Useful Threads!\n",
            "Total Usable DataFrames: 22\n",
            "Small, Unusable DataFrames: 1362\n",
            "Image Posts: 86\n",
            "Number of instances in concat DF: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24d4a3d8-0b62-4b52-80ee-239aee86c649\", \"menstruation.csv\", 52030)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- WORKING ON SUBREDDIT: badwomensanatomy --------------\n",
            "Retreiving posts...\n",
            "Retreived posts!\n",
            "                                                  title  \\\n",
            "0                           Rule 7 update - please read   \n",
            "1                       apparently only ugly women fart   \n",
            "2                              does this one fut here ?   \n",
            "3     On a post about someone with ADHD not being ab...   \n",
            "4                       Explain yourselves lesbians! /s   \n",
            "...                                                 ...   \n",
            "1519                                   Wtf is a vulva ðŸ¤¦   \n",
            "1520  I made a post about how I had an image of my u...   \n",
            "1521                        Not the reddit dm people ðŸ’€ðŸ’€   \n",
            "1522       \"Teaching her in the end she's just a woman\"   \n",
            "1523  Those fluids likely had more to do with her gi...   \n",
            "\n",
            "                                                    url  \n",
            "0     https://www.reddit.com/r/badwomensanatomy/comm...  \n",
            "1                   https://i.redd.it/zirzyvubr9x91.png  \n",
            "2                   https://i.redd.it/o24xau2tmdx91.jpg  \n",
            "3                   https://i.redd.it/d234xh2b88x91.jpg  \n",
            "4                   https://i.redd.it/t36a8cpoh6x91.jpg  \n",
            "...                                                 ...  \n",
            "1519                https://i.redd.it/a0clijpw4ww91.jpg  \n",
            "1520                https://i.redd.it/89m8lf5dltw91.png  \n",
            "1521                https://i.redd.it/po6biy630uw91.jpg  \n",
            "1522                https://i.redd.it/nnilr8h7jsw91.jpg  \n",
            "1523                https://i.redd.it/ybpc941psnw91.jpg  \n",
            "\n",
            "[1524 rows x 2 columns]\n",
            "Finding Useful Threads...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1524/1524 [10:38<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Useful Threads!\n",
            "Total Usable DataFrames: 103\n",
            "Small, Unusable DataFrames: 170\n",
            "Image Posts: 1175\n",
            "Number of instances in concat DF: 895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_872030c1-773c-4812-a85e-700806ebfa41\", \"badwomensanatomy.csv\", 1585306)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- WORKING ON SUBREDDIT: TwoXChromosomes --------------\n",
            "Retreiving posts...\n",
            "Retreived posts!\n",
            "                                                  title  \\\n",
            "0     [MINI FAQ] Do I have to be a woman to particip...   \n",
            "1     Delta paid a doctor to declare a pilot mentall...   \n",
            "2     How do you respectfully explain that there is ...   \n",
            "3     My husband is returning home tonight from a 3 ...   \n",
            "4     Female voter registration for Wisconsin midter...   \n",
            "...                                                 ...   \n",
            "1519        I Have Trouble Believing There Are Good Men   \n",
            "1520  My marriage is going really well but I still f...   \n",
            "1521                             Rape culture on reddit   \n",
            "1522                           Roe, Roe, Roe your vote!   \n",
            "1523          Said goodbye to my Twitter account today.   \n",
            "\n",
            "                                                    url  \n",
            "0     https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "1     https://www.dailykos.com/story/2022/10/29/2131...  \n",
            "2     https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "3     https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "4     https://www.france24.com/en/americas/20221101-...  \n",
            "...                                                 ...  \n",
            "1519  https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "1520  https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "1521  https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "1522  https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "1523  https://www.reddit.com/r/TwoXChromosomes/comme...  \n",
            "\n",
            "[1524 rows x 2 columns]\n",
            "Finding Useful Threads...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1524/1524 [59:58<00:00,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Useful Threads!\n",
            "Total Usable DataFrames: 205\n",
            "Small, Unusable DataFrames: 992\n",
            "Image Posts: 38\n",
            "Number of instances in concat DF: 745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a687f700-2c46-4e35-9964-b3f8c708dc3e\", \"TwoXChromosomes.csv\", 1765146)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7ea1dfb28780cb7412353a3ec0c3d0a6bf48b6a5903db3c2edca4efca070eeb"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}